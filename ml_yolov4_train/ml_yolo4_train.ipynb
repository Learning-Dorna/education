{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-T9teruIuUD"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UC5feMkGIh3v"
      },
      "outputs": [],
      "source": [
        "### roboflow\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"eiYUOfvvafXOToxBN05P\")\n",
        "project = rf.workspace(\"dorna\").project(\"cardamom-good-bad\")\n",
        "version = project.version(28)\n",
        "dataset = version.download(\"darknet\")\n",
        "\n",
        "### parameters ###\n",
        "trained_model_path = \"weight/yolov4_tiny_cardamom_good_bad_max_v5\" # make the directory on the google drive if it doesn't exists\n",
        "trained_model_type = \"last\" # use last or final\n",
        "percentage_test = 5\n",
        "pretrained_model = \"yolov4-tiny.conv.29\"\n",
        "cfg = \"yolov4-tiny-custom\"\n",
        "\n",
        "# get the package\n",
        "!pip install albumentations\n",
        "\n",
        "# imports\n",
        "from google.colab import drive\n",
        "import glob, os\n",
        "import shutil\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "# Augmentation Dictionary\n",
        "augmentation = {\n",
        "    \"run_augmentations\": 0,  # Set to 1 to apply augmentations, 0 to skip\n",
        "    # The p value in all of these augmentations represents the probability of that augmentation being applied.\n",
        "    # \"gauss_noise\": {\"var_limit\": (10.0, 50.0), \"p\": 0},  # The var_limit is the range of variance for adding Gaussian noise to the image.\n",
        "    # \"gaussian_blur\": {\"blur_limit\": (3, 7), \"p\": 0},  # The blur_limit is the range of kernel sizes for applying Gaussian blur to the image.\n",
        "    # \"random_brightness_contrast\": {\"brightness_limit\": 0.2, \"contrast_limit\": 0.2, \"p\": 0},  # The brightness limit defines the change in brightness. Ex: 0.2 means +/-20% change. The contrast limit defines the change in contrast. Ex: 0.2 means +/-20% change.\n",
        "    # \"random_gamma\": {\"gamma_limit\": (50, 130), \"p\": 0},  # The gamma limit defines the range of gamma values for gamma correction. Ex: (50, 130) means the gamma value will be chosen between 50 and 130.\n",
        "    # \"iso_noise\": {\"color_shift\": (0, 0), \"intensity\": (0, 0), \"p\": 0},  # The color shift defines the range of color shift for ISO noise. The intensity defines the range of intensity for ISO noise.\n",
        "    # \"to_gray\": {\"p\": 0},  # The p value represents the probability of converting the image to grayscale.\n",
        "    # \"hue_saturation_value\": {\"hue_shift_limit\": 20, \"sat_shift_limit\": 0, \"val_shift_limit\": 40, \"p\": 0.2},  # The hue shift limit defines the maximum change in hue. The sat shift limit defines the maximum change in saturation. The val shift limit defines the maximum change in value (brightness).\n",
        "    # \"random_scale\": {\"scale_limit\": (0.5, 3), \"p\": 0.5},  # The scale limit defines the range for scaling the image. Ex: (0.6, 2) means the scale factor will be chosen between 0.6 (60%) and 2 (200%). The interpolation method to use. Ex: 1 corresponds to linear interpolation.\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGsI9WQSNuyc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SobmJZ764q4l"
      },
      "outputs": [],
      "source": [
        "# change cfg\n",
        "def update_cfg_file(cfg_file_path, line_changes):\n",
        "    try:\n",
        "        # Read the file\n",
        "        with open(cfg_file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        # Modify specific lines\n",
        "        for line_number, new_value in line_changes.items():\n",
        "            if 0 < line_number <= len(lines):\n",
        "                lines[line_number - 1] = new_value  # Adjusting for 0-based index\n",
        "            else:\n",
        "                print(f\"Line {line_number} is out of range. Skipping.\")\n",
        "\n",
        "        # Write the changes back to the file\n",
        "        with open(cfg_file_path, 'w') as file:\n",
        "            file.writelines(lines)\n",
        "\n",
        "        print(f\"Updated specific lines in {cfg_file_path}.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File {cfg_file_path} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "# helper function\n",
        "def data_prep(percentage_test, current_dir=\"/content/darknet/data\"):\n",
        "\n",
        "  file_train = open(current_dir+'/train.txt', 'w')\n",
        "  file_test = open(current_dir+'/test.txt', 'w')\n",
        "\n",
        "  counter = 1\n",
        "  index_test = round(100 / percentage_test)\n",
        "  for pathAndFilename in glob.iglob(os.path.join(current_dir+\"/obj/\", \"*.jpg\")):\n",
        "      title, ext = os.path.splitext(os.path.basename(pathAndFilename))\n",
        "\n",
        "      if counter == index_test:\n",
        "          counter = 1\n",
        "          file_test.write(current_dir + \"/obj/\" + title + '.jpg' + \"\\n\")\n",
        "      else:\n",
        "          file_train.write(current_dir + \"/obj/\" + title + '.jpg' + \"\\n\")\n",
        "          counter = counter + 1\n",
        "\n",
        "\n",
        "# create .obj data\n",
        "def create_obj_data(classes, file_path=\"/content/darknet/data/obj.data\"):\n",
        "    # Define the content with a placeholder for classes\n",
        "    content = f\"\"\"classes = {classes}\n",
        "train  = /content/darknet/data/train.txt\n",
        "valid  = /content/darknet/data/test.txt\n",
        "names = /content/darknet/data/obj.names\n",
        "backup = /content/darknet/backup\n",
        "\"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "    # Write the content to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "# find classes\n",
        "def find_classes(folder_path):\n",
        "    # Search for .labels files in the specified folder\n",
        "    labels_files = [f for f in os.listdir(folder_path) if f.endswith('.labels')]\n",
        "\n",
        "    # If no .labels file is found, return an empty list\n",
        "    if not labels_files:\n",
        "        return []\n",
        "\n",
        "    # Assuming we want the first found .labels file\n",
        "    labels_file_path = os.path.join(folder_path, labels_files[0])\n",
        "\n",
        "    # Read the lines of the file into a list\n",
        "    with open(labels_file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    return [line.strip() for line in lines]  # Remove any extra newline characters\n",
        "\n",
        "def count_images(image_folder):\n",
        "    return len([f for f in os.listdir(image_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
        "\n",
        "# dataset\n",
        "dataset_path = dataset.location\n",
        "\n",
        "# connect to drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# clone the darknet repo\n",
        "!git clone https://github.com/AlexeyAB/darknet\n",
        "\n",
        "# make\n",
        "%cd /content/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile\n",
        "!make\n",
        "\n",
        "# create cfg\n",
        "%cd data/\n",
        "!find -maxdepth 1 -type f -exec rm -rf {} \\;\n",
        "%cd ..\n",
        "\n",
        "# find num_classes, max_batches, filters, steps\n",
        "classes = find_classes(dataset_path+\"/train\")\n",
        "num_classes = len(classes)\n",
        "\n",
        "# backup backup files\n",
        "!mkdir /content/darknet/backup\n",
        "\n",
        "# move all the train data to data\n",
        "!mkdir /content/darknet/data/obj\n",
        "!mv \"$dataset_path\"/train/* /content/darknet/data/obj/\n",
        "\n",
        "# Create the obj.data file\n",
        "create_obj_data(num_classes)\n",
        "\n",
        "#change the directory to match that of the names file in your drive.\n",
        "!mv /content/darknet/data/obj/_darknet.labels /content/darknet/data/obj.names\n",
        "\n",
        "# pretrained weights\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/\"$pretrained_model\"\n",
        "\n",
        "\n",
        "#Augmentations\n",
        "bbox_params = A.BboxParams(format='yolo', label_fields=['class_labels'])\n",
        "\n",
        "def get_transforms(augmentation):\n",
        "    transforms = []\n",
        "    if augmentation[\"gaussian_blur\"][\"p\"] > 0:\n",
        "        transforms.append(A.GaussianBlur(blur_limit=augmentation[\"gaussian_blur\"][\"blur_limit\"], p=augmentation[\"gaussian_blur\"][\"p\"]))\n",
        "    if augmentation[\"random_brightness_contrast\"][\"p\"] > 0:\n",
        "        transforms.append(A.RandomBrightnessContrast(brightness_limit=augmentation[\"random_brightness_contrast\"][\"brightness_limit\"], contrast_limit=augmentation[\"random_brightness_contrast\"][\"contrast_limit\"], p=augmentation[\"random_brightness_contrast\"][\"p\"]))\n",
        "    if augmentation[\"random_gamma\"][\"p\"] > 0:\n",
        "        transforms.append(A.RandomGamma(gamma_limit=augmentation[\"random_gamma\"][\"gamma_limit\"], p=augmentation[\"random_gamma\"][\"p\"]))\n",
        "    if augmentation[\"hue_saturation_value\"][\"p\"] > 0:\n",
        "        transforms.append(A.HueSaturationValue(hue_shift_limit=augmentation[\"hue_saturation_value\"][\"hue_shift_limit\"], sat_shift_limit=augmentation[\"hue_saturation_value\"][\"sat_shift_limit\"], val_shift_limit=augmentation[\"hue_saturation_value\"][\"val_shift_limit\"], p=augmentation[\"hue_saturation_value\"][\"p\"]))\n",
        "    if augmentation[\"random_scale\"][\"p\"] > 0:\n",
        "        transforms.append(A.RandomScale(scale_limit=augmentation[\"random_scale\"][\"scale_limit\"], p=augmentation[\"random_scale\"][\"p\"]))\n",
        "    #if augmentation[\"shift_scale_rotate\"][\"p\"] > 0:\n",
        "    #    transforms.append(A.ShiftScaleRotate(shift_limit=augmentation[\"shift_scale_rotate\"][\"shift_limit\"], scale_limit=augmentation[\"shift_scale_rotate\"][\"scale_limit\"], rotate_limit=augmentation[\"shift_scale_rotate\"][\"rotate_limit\"], p=augmentation[\"shift_scale_rotate\"][\"p\"]))\n",
        "    #if augmentation[\"random_dynamic_resized_crop\"][\"p\"] > 0:\n",
        "    #    transforms.append(A.RandomResizedCrop(height=augmentation[\"random_dynamic_resized_crop\"][\"max_size\"], width=augmentation[\"random_dynamic_resized_crop\"][\"max_size\"], scale=augmentation[\"random_dynamic_resized_crop\"][\"scale\"], p=augmentation[\"random_dynamic_resized_crop\"][\"p\"]))\n",
        "    #if augmentation[\"pad_if_needed\"][\"p\"] > 0:\n",
        "    #     transforms.append(A.PadIfNeeded(min_height=augmentation[\"pad_if_needed\"][\"min_height\"], min_width=augmentation[\"pad_if_needed\"][\"min_width\"], border_mode=augmentation[\"pad_if_needed\"][\"padding_mode\"], p=augmentation[\"pad_if_needed\"][\"p\"]))\n",
        "\n",
        "    return A.Compose(transforms, bbox_params=bbox_params) if transforms else None\n",
        "\n",
        "def augment_image(image, bboxes, class_labels, num_augmentations, transform):\n",
        "    \"\"\"Apply augmentations multiple times to an image and its bounding boxes.\"\"\"\n",
        "    augmented_images = []\n",
        "    augmented_bboxes_list = []\n",
        "    augmented_labels_list = []\n",
        "\n",
        "    for _ in range(num_augmentations):\n",
        "        augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        augmented_images.append(augmented['image'])\n",
        "        augmented_bboxes_list.append(augmented['bboxes'])\n",
        "        augmented_labels_list.append(augmented['class_labels'])\n",
        "\n",
        "    return augmented_images, augmented_bboxes_list, augmented_labels_list\n",
        "\n",
        "def process_directory(image_dir, annotations_dir, output_dir, num_augmentations=5):\n",
        "    \"\"\"Process images and annotations in a directory.\"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    # Get transformation based on the augmentation dictionary\n",
        "    transform = get_transforms(augmentation) if augmentation[\"run_augmentations\"] == 1 else None\n",
        "\n",
        "    for image_file in image_files:\n",
        "        # Load image\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Load bounding boxes\n",
        "        annotation_file = image_file.replace('.jpg', '.txt').replace('.png', '.txt')\n",
        "        annotations_path = os.path.join(annotations_dir, annotation_file)\n",
        "        bboxes = []\n",
        "        class_labels = []\n",
        "        with open(annotations_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_labels.append(int(parts[0]))\n",
        "                    x_center, y_center, width, height = map(float, parts[1:])\n",
        "                    bboxes.append([x_center, y_center, width, height])\n",
        "\n",
        "        if transform:\n",
        "            # Augment image and bounding boxes multiple times\n",
        "            augmented_images, augmented_bboxes_list, augmented_labels_list = augment_image(image, bboxes, class_labels, num_augmentations, transform)\n",
        "\n",
        "            # Save augmented images and bounding boxes\n",
        "            for i, (augmented_image, augmented_bboxes, augmented_labels) in enumerate(zip(augmented_images, augmented_bboxes_list, augmented_labels_list)):\n",
        "                # Save augmented image\n",
        "                augmented_image_path = os.path.join(output_dir, f\"{os.path.splitext(image_file)[0]}_aug_{i}.jpg\")\n",
        "                cv2.imwrite(augmented_image_path, augmented_image)\n",
        "\n",
        "                # Save augmented bounding boxes with their correct class labels\n",
        "                augmented_annotations_path = os.path.join(output_dir, f\"{os.path.splitext(image_file)[0]}_aug_{i}.txt\")\n",
        "                with open(augmented_annotations_path, 'w') as f:\n",
        "                    for label, bbox in zip(augmented_labels, augmented_bboxes):\n",
        "                        f.write(f\"{label} {' '.join(map(str, bbox))}\\n\")\n",
        "        else:\n",
        "            # If no augmentation, just copy the original image and annotations\n",
        "            output_image_path = os.path.join(output_dir, image_file)\n",
        "            cv2.imwrite(output_image_path, image)\n",
        "\n",
        "            output_annotation_path = os.path.join(output_dir, annotation_file)\n",
        "            with open(annotations_path, 'r') as f:\n",
        "                content = f.read()\n",
        "            with open(output_annotation_path, 'w') as f:\n",
        "                f.write(content)\n",
        "\n",
        "# Path to the directories\n",
        "image_dir = '/content/darknet/data/obj'\n",
        "annotations_dir = '/content/darknet/data/obj'\n",
        "output_dir = '/content/darknet/data/obj'\n",
        "\n",
        "# Process the directory\n",
        "process_directory(image_dir, annotations_dir, output_dir, num_augmentations=5)\n",
        "\n",
        "print(\"Augmentation complete.\")\n",
        "# create train and test\n",
        "data_prep(percentage_test)\n",
        "\n",
        "# Directory with images\n",
        "image_folder = \"/content/darknet/data/obj\"\n",
        "# Count the number of images\n",
        "num_images = count_images(image_folder)\n",
        "# Calculate max_batches\n",
        "max_batches = max(6000, num_classes * 2000, num_images)\n",
        "# Calculate steps\n",
        "steps = f\"{int(max_batches * 0.8)},{int(max_batches * 0.9)}\"\n",
        "# lines to be changed\n",
        "line_changes = {\n",
        "    6: 'batch=64\\n',\n",
        "    7: 'subdivisions=16\\n',\n",
        "    8: 'width=416\\n',\n",
        "    9: 'height=416\\n',\n",
        "    20: f'max_batches={max_batches}\\n',  # Adjust based on `num_classes`, `num_images`\n",
        "    22: f'steps={steps}\\n',  # Adjust based on `max_batches`\n",
        "    220: f'classes={num_classes}\\n',  # Adjust based on `num_classes`\n",
        "    269: f'classes={num_classes}\\n',  # Adjust based on `num_classes`\n",
        "    212: f'filters={(num_classes + 5) * 3}\\n',  # Adjust based on `num_classes`\n",
        "    263: f'filters={(num_classes + 5) * 3}\\n'   # Adjust based on `num_classes`\n",
        "}\n",
        "\n",
        "update_cfg_file(\"/content/darknet/cfg/\"+cfg+\".cfg\", line_changes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y71_GtA3N9dp"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ioz7Y07LFxJc"
      },
      "outputs": [],
      "source": [
        "#This is the training block, it will take some time.\n",
        "!./darknet detector train /content/darknet/data/obj.data /content/darknet/cfg/\"$cfg\".cfg /content/darknet/\"$pretrained_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCSQg3U7MFNQ"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ_JkhUeMizN"
      },
      "outputs": [],
      "source": [
        "# model path\n",
        "model_path = \"/content/darknet/backup/\"+cfg+\"_\"+trained_model_type+\".weights\"\n",
        "cfg_path = \"/content/darknet/cfg/\"+cfg+\".cfg\"\n",
        "\n",
        "#Set your custom cfg to evaluation mode.\n",
        "!sed -i 's/batch=64/batch=1/' \"$cfg_path\"\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' \"$cfg_path\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uybH2xgmMS_8"
      },
      "outputs": [],
      "source": [
        "#Use can use this line to check the mAP for all the diffrent weights to see which gives the best results (change the directory to match yours).\n",
        "!./darknet detector map /content/darknet/data/obj.data \"$cfg_path\" \"$model_path\" -points 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APLcfDbeMqDV"
      },
      "outputs": [],
      "source": [
        "#Run on Image (change the directories to match yours).\n",
        "# Find the result at /content/darknet/predictions.jpg\n",
        "test_image_path = \"/content/5053170388753821383.jpg\"\n",
        "!./darknet detector test /content/darknet/data/obj.data \"$cfg_path\" \"$model_path\" \"$test_image_path\" -thresh 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgZbdCRJAK9-"
      },
      "source": [
        "# Darknet -> ncnn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MGbQQXyxAM0w"
      },
      "outputs": [],
      "source": [
        "# Clone the NCNN repository\n",
        "%cd /content\n",
        "!git clone https://github.com/Tencent/ncnn.git\n",
        "%cd ncnn\n",
        "\n",
        "# Create a build directory and navigate to it\n",
        "!rm -rf build\n",
        "!mkdir build\n",
        "%cd build\n",
        "\n",
        "# Configure the build\n",
        "!cmake ..\n",
        "!make -j4\n",
        "\n",
        "# darknet to ncnn\n",
        "%cd /content/ncnn/build/tools/darknet\n",
        "!./darknet2ncnn \"$cfg_path\" \"$model_path\" /content/model.param /content/model.bin 1\n",
        "\n",
        "# optimize\n",
        "%cd ..\n",
        "!./ncnnoptimize /content/model.param /content/model.bin /content/model_opt.param /content/model_opt.bin 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF5teZ9E3zVD"
      },
      "source": [
        "# Save data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYhV2L-Q317d"
      },
      "outputs": [],
      "source": [
        "# Copy the optimized model to Google Drive\n",
        "shutil.copy(\"/content/model_opt.bin\", \"/content/drive/My Drive/\"+trained_model_path+\".bin\")\n",
        "shutil.copy(\"/content/model_opt.param\", \"/content/drive/My Drive/\"+trained_model_path+\".param\")\n",
        "\n",
        "# Copy the file to Google Drive\n",
        "shutil.copy(model_path, \"/content/drive/My Drive/\"+trained_model_path+\".weights\")\n",
        "shutil.copy(cfg_path, \"/content/drive/My Drive/\"+trained_model_path+\".cfg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
